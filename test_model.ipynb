{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a28fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_nlg import RecipeNLGDataset, TokenizedRecipeNLGDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/recipenlg\")\n",
    "# Load the dataset\n",
    "df = pd.read_csv(path + \"/RecipeNLG_dataset.csv\", header=0)\n",
    "# Create an instance of the RecipeNLGDataset class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093b7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer_path = Path(\"title_to_all_tokenizer\")\n",
    "print(\"Loading tokenizer\")\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path, model_max_lenth=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'all' is default mode\n",
    "data = RecipeNLGDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d3c7e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1146,    12,   300,  ...,     0,     0,     0],\n",
       "        [13024,    66,   842,  ...,     0,     0,     0],\n",
       "        [ 1425,   442,     2,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 1767,   610,   679,  ...,     0,     0,     0],\n",
       "        [ 1725,  1183,     9,  ...,     0,     0,     0],\n",
       "        [  327,  1604,   348,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_batch = data.recipe_strings[:16]\n",
    "\n",
    "tokenized_batch = hf_tokenizer(\n",
    "    text=recipe_batch.tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "tokenized_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c4a9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_format = {\n",
    "    \"input_ids\": tokenized_batch[\"input_ids\"].squeeze(0),\n",
    "    \"attention_mask\": tokenized_batch[\"attention_mask\"].squeeze(0),\n",
    "    # etc.\n",
    "}\n",
    "\n",
    "print(proper_format[\"attention_mask\"].shape)\n",
    "proper_format[\"input_ids\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "016dd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 16\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "hf_ds = Dataset.from_dict({\n",
    "    k: v.numpy()  # Datasets accepts numpy arrays\n",
    "    for k, v in proper_format.items()\n",
    "})\n",
    "\n",
    "print(hf_ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f245269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    # Convert each field in the batch to a PyTorch tensor\n",
    "    return {\n",
    "        key: torch.stack([torch.tensor(item[key]) for item in batch])\n",
    "        for key in batch[0]\n",
    "    }\n",
    "\n",
    "loader = DataLoader(hf_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    print(batch['input_ids'].shape) # (batch size, max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
