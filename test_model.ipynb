{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a28fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_nlg import RecipeNLGDataset, TokenizedRecipeNLGDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/recipenlg\")\n",
    "# Load the dataset\n",
    "df = pd.read_csv(path + \"/RecipeNLG_dataset.csv\", header=0)\n",
    "# Create an instance of the RecipeNLGDataset class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093b7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer_path = Path(\"title_to_all_tokenizer\")\n",
    "print(\"Loading tokenizer\")\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path, model_max_lenth=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212c36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'all' is default mode\n",
    "data = RecipeNLGDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3c7e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1146,    12,   300,  ...,     0,     0,     0],\n",
       "        [13024,    66,   842,  ...,     0,     0,     0],\n",
       "        [ 1425,   442,     2,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 1767,   610,   679,  ...,     0,     0,     0],\n",
       "        [ 1725,  1183,     9,  ...,     0,     0,     0],\n",
       "        [  327,  1604,   348,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_batch = data.recipe_strings[:16]\n",
    "\n",
    "tokenized_batch = hf_tokenizer(\n",
    "    text=recipe_batch.tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "tokenized_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4a9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_format = {\n",
    "    \"input_ids\": tokenized_batch[\"input_ids\"].squeeze(0),\n",
    "    \"attention_mask\": tokenized_batch[\"attention_mask\"].squeeze(0),\n",
    "    # etc.\n",
    "}\n",
    "\n",
    "print(proper_format[\"attention_mask\"].shape)\n",
    "proper_format[\"input_ids\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016dd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 16\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "hf_ds = Dataset.from_dict({\n",
    "    k: v.numpy()  # Datasets accepts numpy arrays\n",
    "    for k, v in proper_format.items()\n",
    "})\n",
    "\n",
    "print(hf_ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f245269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    # Convert each field in the batch to a PyTorch tensor\n",
    "    return {\n",
    "        key: torch.stack([torch.tensor(item[key]) for item in batch])\n",
    "        for key in batch[0]\n",
    "    }\n",
    "\n",
    "loader = DataLoader(hf_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    print(batch['input_ids'].shape) # (batch size, max_length) -> this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb3ad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scalloped corn <end_title> 1 can cream - style corn , 1 can whole kernel corn , 12 pkg . ( approximately 20 ) saltine crackers , crushed , 1 egg , beaten , 6 tsp . butter , divided , pepper to taste <end_ingredients> mix together both cans of corn , crackers , egg , 2 teaspoons of melted butter and pepper and place in a buttered baking dish . dot with remaining 4 teaspoons of butter . bake at 350u00b0 for 1 hour . <end> [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure decoding works\n",
    "first_batch = next(iter(loader))\n",
    "first_example = first_batch['input_ids'][0]\n",
    "hf_tokenizer.decode(first_example)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcddc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 66])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_ids = first_batch['input_ids']\n",
    "\n",
    "vocab_size = len(hf_tokenizer.get_vocab())\n",
    "d_model = 66\n",
    "context_length = 512\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# embedding layer: one row for every token in vocab, embedding-size columns\n",
    "embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "\n",
    "x = embedding(input_ids)\n",
    "x.shape # (batchsize x seq_length x embed dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef8ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 66])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 66])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from PositionalEncoder import PositionalEncoder\n",
    "\n",
    "\n",
    "pe = PositionalEncoder(d_model=d_model, context_len=context_length)\n",
    "\n",
    "pe.pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe8ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 66])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it gets through the positional encoder!\n",
    "x = pe(x)\n",
    "\n",
    "x.shape # shape (batch, context, dmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0837fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 66])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import DecoderBlock\n",
    "\n",
    "test_decoder = DecoderBlock(num_heads=2, d_model=d_model, num_hidden_layers=2, d_hidden=2048)\n",
    "x = test_decoder(x)\n",
    "\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
