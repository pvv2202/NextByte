{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a28fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_nlg import RecipeNLGDataset, TokenizedRecipeNLGDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import kagglehub\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/recipenlg\")\n",
    "# Load the dataset\n",
    "df = pd.read_csv(path + \"/RecipeNLG_dataset.csv\", header=0)\n",
    "# Create an instance of the RecipeNLGDataset class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093b7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer_path = Path(\"Tokenizers/title_to_all_tokenizer\")\n",
    "print(\"Loading tokenizer\")\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path, model_max_lenth=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212c36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'all' is default mode\n",
    "data = RecipeNLGDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3c7e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 1146,    12,   300,  ...,     0,     0,     0],\n",
       "        [13024,    66,   842,  ...,     0,     0,     0],\n",
       "        [ 1425,   442,     2,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 1767,   610,   679,  ...,     0,     0,     0],\n",
       "        [ 1725,  1183,     9,  ...,     0,     0,     0],\n",
       "        [  327,  1604,   348,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_batch = data.recipe_strings[:16]\n",
    "\n",
    "tokenized_batch = hf_tokenizer(\n",
    "    text=recipe_batch.tolist(),\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "tokenized_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4a9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proper_format = {\n",
    "    \"input_ids\": tokenized_batch[\"input_ids\"],\n",
    "    \"attention_mask\": tokenized_batch[\"attention_mask\"],\n",
    "    \"labels\": tokenized_batch[\"input_ids\"]\n",
    "    # etc.\n",
    "}\n",
    "\n",
    "print(proper_format[\"attention_mask\"].shape)\n",
    "proper_format[\"labels\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016dd65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 16\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "hf_ds = Dataset.from_dict({\n",
    "    k: v.numpy()  # Datasets accepts numpy arrays\n",
    "    for k, v in proper_format.items()\n",
    "})\n",
    "\n",
    "print(hf_ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f245269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    # Convert each field in the batch to a PyTorch tensor\n",
    "    return {\n",
    "        key: torch.stack([torch.tensor(item[key]) for item in batch])\n",
    "        for key in batch[0]\n",
    "    }\n",
    "\n",
    "loader = DataLoader(hf_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for i, batch in enumerate(loader):\n",
    "    print(batch['input_ids'].shape) # (batch size, max_length) -> this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb3ad55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick barbecue wings <end_title> chicken wings ( as many as you need for dinner ) , flour , barbecue sauce ( your choice ) <end_ingredients> clean wings . flour and fry until done . place fried chicken wings in microwave bowl . stir in barbecue sauce . microwave on high ( stir once ) for 4 minutes . <end> [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure decoding works\n",
    "first_batch = next(iter(loader))\n",
    "first_example = first_batch['input_ids'][0]\n",
    "first_labels = first_batch['labels'][0]\n",
    "print(hf_tokenizer.decode(first_example))\n",
    "first_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcddc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from models import NextByteTransformer\n",
    "\n",
    "test_input = first_example.unsqueeze(0)\n",
    "\n",
    "vocab_size = len(hf_tokenizer.get_vocab())\n",
    "d_model = 66\n",
    "context_length = 512\n",
    "\n",
    "next_byte = NextByteTransformer(\n",
    "    d_model=d_model,\n",
    "    vocab_size=vocab_size,\n",
    "    context_length=context_length,\n",
    "    # each head handles half of embedding context\n",
    "    num_heads=2, \n",
    "    num_hidden_layers=2, \n",
    "    d_hidden=2048, \n",
    "    num_decoders=6)\n",
    "\n",
    "test_input.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0deefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 20000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = next_byte(test_input)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d52cca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first token was: quick\n",
      "pred next token was: ##allo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_token_id = test_input[0][0]\n",
    "first_pred_id = torch.argmax(logits[0][0])\n",
    "# first_pred_idx = torch.argmax(logits[0])\n",
    "# first_token_id = test_input[1][0]\n",
    "\n",
    "print(f\"first token was: {hf_tokenizer.decode(first_token_id)}\")\n",
    "print(f\"pred next token was: {hf_tokenizer.decode(first_pred_id)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
