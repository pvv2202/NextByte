{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-04T17:43:58.137761Z",
     "start_time": "2025-05-04T17:43:57.275164Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from pathlib import Path\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from models import NextByteTransformer\n",
    "\n",
    "context_length = 512\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_hidden_layers = 8\n",
    "d_hidden = 2048\n",
    "num_decoders = 2\n",
    "num_epochs = 8\n",
    "lr = 3e-5\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\"\"\"Load title to ingredients model\"\"\"\n",
    "tokenizer_path = Path(\"Tokenizers/title_to_ingredients_tokenizer\")\n",
    "title_to_ingredients_tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n",
    "title_to_ingredients_tokenizer.eos_token_id = title_to_ingredients_tokenizer.convert_tokens_to_ids(\"<end>\")\n",
    "title_to_ingredients_model = NextByteTransformer(\n",
    "    vocab_size=20000,\n",
    "    context_length=context_length,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    d_hidden=d_hidden,\n",
    "    num_decoders=num_decoders\n",
    ").to(device)\n",
    "\n",
    "title_to_ingredients_model.load_state_dict(torch.load(\"Models/title_to_ingredients.pth\", map_location=device))\n",
    "title_to_ingredients_model.eval()\n",
    "\n",
    "\"\"\"Load ingredients to directions model\"\"\"\n",
    "tokenizer_path = Path(\"Tokenizers/ingredients_to_directions_tokenizer\")\n",
    "ingredients_to_directions_tokenizer = PreTrainedTokenizerFast.from_pretrained(tokenizer_path)\n",
    "ingredients_to_directions_tokenizer.eos_token_id = ingredients_to_directions_tokenizer.convert_tokens_to_ids(\"<end>\")\n",
    "ingredients_to_directions_model = NextByteTransformer(\n",
    "    vocab_size=20000,\n",
    "    context_length=context_length,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    d_hidden=d_hidden,\n",
    "    num_decoders=num_decoders\n",
    ").to(device)\n",
    "\n",
    "ingredients_to_directions_model.load_state_dict(torch.load(\"Models/ingredients_to_directions.pth\", map_location=device))\n",
    "ingredients_to_directions_model.eval()\n",
    "\n",
    "def generate_autoregressive(model, tokenizer, input_text, max_new_tokens=100, top_k=10, context_length=512, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    input_ids = input_ids[:, -context_length:]\n",
    "    generated = input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            if generated.size(1) > context_length:\n",
    "                generated = generated[:, -context_length:]\n",
    "\n",
    "            logits = model(generated)[:, -1, :]  # shape: [1, vocab_size]\n",
    "            topk_logits, topk_indices = torch.topk(logits, k=top_k, dim=-1)\n",
    "            probs = F.softmax(topk_logits, dim=-1)\n",
    "\n",
    "            sampled_index = torch.multinomial(probs, num_samples=1)  # shape: [1, 1]\n",
    "            next_token = topk_indices.gather(-1, sampled_index)  # shape: [1, 1]\n",
    "\n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "\n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "\n",
    "    return tokenizer.decode(generated[0], skip_special_tokens=False)\n",
    "\n",
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "\n",
    "count_parameters(title_to_ingredients_model)\n",
    "count_parameters(ingredients_to_directions_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 75,312,672\n",
      "Trainable parameters: 75,312,672\n",
      "Total parameters: 75,312,672\n",
      "Trainable parameters: 75,312,672\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:44:28.388582Z",
     "start_time": "2025-05-04T17:44:18.527162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"Run through title to ingredients model\"\"\"\n",
    "input_text = \"chicken tikka masala <end_title>\"\n",
    "output1 = generate_autoregressive(\n",
    "    model=title_to_ingredients_model,\n",
    "    tokenizer=title_to_ingredients_tokenizer,\n",
    "    input_text=input_text,\n",
    "    max_new_tokens=400,\n",
    "    top_k=10,\n",
    "    context_length=context_length,\n",
    ")\n",
    "title_index = output1.find(\"<end_title>\")\n",
    "title = output1[:title_index]\n",
    "ingredients = output1[title_index + len(\"<end_title>\"):]\n",
    "\n",
    "\"\"\"Run through ingredients to directions model\"\"\"\n",
    "output2 = generate_autoregressive(\n",
    "    model=ingredients_to_directions_model,\n",
    "    tokenizer=ingredients_to_directions_tokenizer,\n",
    "    input_text=ingredients.replace(\"<end>\", \"<end_ingredients>\"),\n",
    "    max_new_tokens=400,\n",
    "    top_k=10,\n",
    "    context_length=context_length,\n",
    ")\n",
    "title = re.sub(r'\\s+([.,!?;:])', r'\\1', title)\n",
    "ingredients = re.sub(r'\\s+([.,!?;:])', r'\\1', ingredients[:-len(\"<end_ingredients>\")])\n",
    "directions = re.sub(r'\\s+([.,!?;:])', r'\\1', output2[output2.find(\"<end_ingredients>\") + len(\"<end_ingredients>\"):-len(\"<end>\")])\n",
    "\n",
    "\n",
    "print(f\"Recipe: \\n{title.title()}\\n\")\n",
    "print(f\"Ingredients: \\n{ingredients.title()}\\n\")\n",
    "print(f\"Directions: \\n{directions.title()}\\n\")"
   ],
   "id": "c10b1abd6e704e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken tikka masala <end_title> 3 large boneless chicken breasts , 2 teaspoons olive oil , 1 ( 8 - ounce ) carton sour cream , 2 ( 8 12 - ounce ) containers plain yogurt ( such as whole - milk , i like to use fresh ground pepper , 12 cup plain nonfat greek yogurt , 14 cup finely chopped fresh cilantro or parsley , 3 tablespoons chopped fresh cilantro , 3 tablespoons chopped fresh mint leaves , salt , to taste , 12 cup freshly ground black pepper , 12 teaspoon ground cumin , 34 cup shredded reduced - fat cheddar cheese , 1 ( 6 - ounce ) package mixed baby greens <end>\n",
      "Recipe: \n",
      "Chicken Tikka Masala \n",
      "\n",
      "Ingredients: \n",
      " 3 Large Boneless Chicken Breasts, 2 Teaspoons Olive Oil, 1 ( 8 - Ounce ) Carton Sour Cream, 2 ( 8 12 - Ounce ) Containers Plain Yogurt ( Such As Whole - Milk, I Like To Use Fresh Ground Pepper, 12 Cup Plain Nonfat Greek Yogurt, 14 Cup Finely Chopped Fresh Cilantro Or Parsley, 3 Tablespoons Chopped Fresh Cilantro, 3 Tablespoons Chopped Fresh Mint Leaves, Salt, To Taste, 12 Cup Freshly Ground Black Pepper, 12 Teaspoon Ground Cumin, 34 Cup Shredded Reduced - Fat Cheddar Cheese, 1 ( 6 - Ounce ) Package Mixed \n",
      "\n",
      "Directions: \n",
      " Preheat The Oven To 375 Degrees F. Line A Baking Sheet With Foil. Place The Chicken Breasts On The Prepared Baking Sheet With The Olive Oil, Then Sprinkle With The Salt And Pepper, Then Drizzle The Chicken With The Olive Oil. Roast The Chicken Breasts In The Oven For 25 Minutes, Until Golden And Crispy. Transfer To A Cutting Board And Cut The Chicken Into Bite - Size Pieces. Place The Chicken On The Rack, And Roast For 30 To 40 Minutes, Or Until The Skin Becomes Brown And Crispy. Let Rest For 10 Minutes And Then Thinly Slice Across. In A Bowl Toss Together Chopped Fresh Cilantro Sprigs. In A Medium Bowl, Combine The Chicken, Cilantro, Mint, And The 12 Cup Of Chopped Chives And Toss Gently With The Chicken. Season To Taste With Salt And Pepper. Transfer The Chicken Back To The Oven And Bake Until Done, About 10 Minutes. Remove From The Oven And Top With The Cheese, Toasted Pine Nuts, Cilantro, And A Small Spoonful Of The Yogurt Sauce. Serve With The Salad And Cheese Sauce. \n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
